model_to_use: xgboost_simple #model from the models module
columns: #columns to use, we set the target, the columns to use and of those which are categorical
  target: 'percentage_docks_available'
  useful: ['month', 'day', 'hour', 'ctx-4', 'ctx-3', 'ctx-2', 'ctx-1', 'lat', 'lon', 'altitude', 'icon', 'humidity', 'windspeed', 'precip', 'temp']
  categorical: ['month', 'day', 'hour', 'icon']

preprocessing: #controls the preprocessing pipeline
  bicing_cols:  # columns to use from bicing data
    - 'station_id'
    - 'last_reported'
    - 'num_bikes_available'
    - 'is_installed'
    - 'is_renting'
    - 'status'

  station_cols: # columns to use from the station info data
    - 'station_id'
    - 'name'
    - 'lat'
    - 'lon'
    - 'capacity'
    - 'altitude'

  meteo_cols: # columns to use from meteo data
    - 'year'
    - 'month'
    - 'day'
    - 'hour'
    - 'temp'
    - 'humidity'
    - 'windspeed'
    - 'precip'
    - 'icon'
  use_meteo_data: False
  use_test: False
  fetch_data: True
  save_file: True
  output_name_train: train_dataset.csv
  output_name_sub: sub_dataset.csv

train: #controls the model trainer
  mlflow:
    tracking_uri: 'http://127.0.0.1:5000'
    mlflow_experiment: 'xgboost'
    mlflow_run: 'full_pipeline_fixed_test'
  tuning: 
    mode: 'standard' # can be standard or custom. If custom, create a new class inheriting from BaseModelTrainer and write a custom train method
    strategy: random # can be either random or grid
    n_iter: 3 # Only necessary for random strategy
    parameters: # use model__ prefix so that the sklearn pipeline will detect the parameters.
      model__alpha: [0.4, 0.5, 0.6]
      model__colsample_bytree: [0.9, 1]
      model__gamma: [0,0.1]
      model__lambda: [0.4, 0.5]
      model__learning_rate: [0.1, 0.2, 0.3]
      model__max_depth: [6,7,8]

    
pipeline: # train.py, which pipelines to use
  preprocess: True
  train: True

  

    